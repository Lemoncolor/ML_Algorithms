# encoding: utf-8
"""
 @project:ML_Algorithms
 @author: Jiang Hui
 @language:Python 3.7.2 [GCC 7.3.0] :: Anaconda, Inc. on linux
 @time: 4/2/19 9:17 AM
 @desc:
"""
# 强烈建议学习本算法之前，阅读我整理的关于概率、似然、极大似然估计的学习笔记
# https://blog.csdn.net/jh1137921986/article/details/89000994
"""
 引子：
    EM算法也称期望最大化(Expectation Maximum)算法，它是一个基础算法，是很多机器学习领域算法的基础，比如隐式马尔科夫算法(HMM)，LDA主题
 模型等.EM算法是一种迭代算法，用于含有隐变量的概率模型参数的极大似然估计，EM的每次迭代分两个过程，一是E步，求期望；二是M步，求极大.
"""

"""
 1.根据一个实例，来确切感受EM算法    【参考《统计学习方法》P155 例9.1】
    
    假如有3枚硬币，分别记作A，B，C，这些硬币正面出现的概率分别是π，p和q.进行如下投币实验，每轮开始先掷硬币A，根据其结果决定掷硬币B还是C，如果
 A的结果是正面，则掷硬币B，反面则掷硬币C；然后掷选出来的硬币，出现正面记为1，反面记为0，独立地重复10次实验，最终预测结果如下：
                                
                                        (1, 1, 0, 1, 0, 0, 1, 0, 1, 1)
                                        
    假设只能观测到掷硬币的结果，不能观测到掷硬币的过程（即不知道每次的结果是硬币B还是C掷出来的），问这三枚硬币正面朝上的概率分别是多少?
    
    (1)解析：
        我们定义y为观测变量（y是已知量），表示每一轮实验观测到的结果，用随机变量z作为隐变量，表示我们看不到的掷硬币A的结果
    
        θ = (π, p, q)是模型参数，这一模型是以上观测数据的生成模型.
    
        我们已知每轮实验是相互独立的，所以对于某一轮的观测结果y，有：
        
        P(y|θ)即P(y|π;p;q)，表示基于给定的(π, p, q)，求某次观测事件y发生的概率，计算式如下：
        
        P(y|θ) = sum P(y,z|θ)        ，其中z∈{0, 1}
        
               = π * p^y * (1-p)^(1-y) + (1-π) * q^y * (1-q)^(1-y)      # 把y=0和y=1的两种情况综合了起来
            
    (2)提升：
        将观测事件表示为Y=(y1,y2,y3,...,yn)，观测不到的事件表示为Z=(z1,z2,z3,...,zn)，则观测事件的似然函数为：
    
        即：
            L(θ|Y) = P(y1|θ)*P(y2|θ)*P(y3|θ)*...*P(yn|θ)
        
        求模型参数θ=(π, p, q)的极大似然估计，即：
        
            θ*  = arg max log L(θ|Y)
        
        这个问题没有解析解，只能通过迭代的方式求解，过程如下：
        
            (a)初始化参数θ的初值 θ_0 = (π_0,p_0,q_0)
            
            (b)迭代进行下面的EM过程，直至参数收敛位置，第i次迭代的参数值θ_i = (π_i,p_i,q_i)，EM算法的第i+1次迭代如下：
            
                E步：计算在模型参数θ_i下，观测数据y_j来自掷硬币B的概率μ_i+1_j：     【注：来自硬币B，即表示硬币A正面朝上】
                    
                    硬币B得到观测结果y_j的概率，P1 = π_i * p_i^y_j * (1-p_i)^(1-y_j)
                    
                    硬币C得到观测结果y_j的概率，P2 = (1-π_i) * q_i^y_j * (1-q_i)^(1-y_j)
                    
                    第j个观测数据y_j来自硬币B的概率u_i+1_j：  【第j个观测数据y_j来自硬币B 等价于 第j轮硬币A正面朝上】
                    
                                        μ_i+1_j = P1 / (P1 + P2)     
                
                M步：更新模型参数的估计值
                    
                    (m1) π_i+1等于n轮观测数据来自硬币B（硬币A正面朝上）的均值（期望）
                    
                         π_i+1 = 1/n * sum μ_i+1_j       其中j=0,1,2,...,n
                    
                    (m2) p_i+1表示 观测数据y_j来自硬币B并且朝上的概率 除以 观测数据y_j来自硬币B的概率【P(A,B)=P(A)*P(B)的计算形式】
                    
                         p_i+1 = sum μ_i+1_j * y_j / sum μ_i+1_j      其中j=0,1,2,...,n ， y_j取0或1
                    
                    (m3) q_i+1表示 观测数据y_j来自硬币C并且朝上的概率 除以 观测数据y_j来自硬币C的概率
                    
                         q_i+1 = sum (1-μ_i+1_j)*y_j / sum (1-μ_i+1_j)      其中j=0,1,2,...,n
            
            (c)模型参数收敛，迭代完毕，返回模型参数估计值
            
    (3)代入数值计算：已知观测数据y为{1, 1, 0, 1, 0, 0, 1, 0, 1, 1}
        
        (a)第0轮，假设模型的初值取为: π_0 = 0.5 , p_0 = 0.5 , q_0 = 0.5
        
        (b)第1轮，μ_1_1 = μ_1_2 = μ_1_3 = μ_1_4 = ... =u_1_10 = 0.5
        
                π_1 = (0.5+0.5+...+0.5)/10 = 0.5
                p_1 = 0.5*6 / 0.5*10 = 0.6
                q_1 = 0.5*6 / 0.5*10 = 0.6
        
        (c)第2轮，μ_2_1 = μ_2_2 = μ_2_3 = μ_2_4 = ... =u_2_10 = 0.5
        
                π_1 = (0.5+0.5+...+0.5)/10 = 0.5
                p_1 = 0.5*6 / 0.5*10 = 0.6
                q_1 = 0.5*6 / 0.5*10 = 0.6
        
        于是发现模型已经收敛，得到L(θ|Y)取最大似然值时，对应的θ为(0.5,0.6,0.6)
        
        如果取不同的初值进行计算，如θ_0 = (0.4, 0.6, 0.7)，最终的收敛结果为(0.4064, 0.5368, 0.6432)
        
        也就是说，EM算法与模型参数的初值有关，不同的参数设置，最终可能得到不同的参数估计值
        
 2.EM算法的推导（本节结尾的结论十分重要）
    
    上面结合一道例题，简单说了一下EM算法的求解流程，下面进行全面的推导.
    
    对于m条观测数据的集合x = (x_1, x_2, x_3, ..., x_m)，需要找到使得对数似然函数极大化时对应的参数θ：

                            θ = arg max sum log(P(x_i;θ)  ，其中i=1,2,3,...,m，对数似然用累加符号

    如果我们得到的观测数据，每一条还对应着一条未观测的隐含数据z = (z_1, z_2, z_3, ... , z_m)，那么此时的对数似然函数为：
            
            P(x_i;θ) = sum P(x_i,z_j;θ)      其中j=1, 2, 3, ..., m

            θ = arg max sum log( sum P(x_i,z_j;θ) )      其中i,j = 1, 2, 3, ..., m，
                                                        【其中前面的sum是对i累加，后面的sum是对j，下面同理，不做赘述】
            
    上式包括观测不到的数据，无法直接求出θ，于是EM算法通过迭代法，【来逐步近似对数似然函数的极大值!!!】：

        对于 sum log( sum P(x_i,z_j;θ) )    其中i,j = 1, 2, 3, ..., m ，有：
            
            sum log( sum P(x_i,z_j;θ) ) = sum log( sum Q(z_j)*P(x_i,z_j;θ)/Q(z_j) )
            
        其中，假如只分析x_1的对数似然函数，即 log sum Q(z_j)*P(x_1,z_j;θ)/Q(z_j) ，其中j=1,2,3,...,N
        
        我们把Q(z_j)看作是权重，P(x_1,z_j;θ)/Q(z_j)看作是自变量
            
        根据对数函数的性质，log (a1x1+a2x2) >= a1*log x1 + a2*log x2，其中a1+a2=1 （高中数学知识，Jensen不等式，参考百度百科）
        
        于是可得以下这个式子：
        
            log sum Q(z_j)*P(x_1,z_j;θ)/Q(z_j) >= Q(z_j) * log P(x_1,z_j;θ)/Q(z_j)

        那现在我们把所有的i都代进去，可得
        
        sum log( sum Q(z_j)*P(x_i,z_j;θ)/Q(z_j) ) >= sum sum Q(z_j) * log P(x_i,z_j;θ)/Q(z_j)   【运用了琴生不等式】
                                      
        这个过程可以看作是对数似然函数取得了下界，那么对于Q(z_j)的值如何选择呢?这个下界取决于Q(z_j)和P(x_i,z_j;θ)，我们可以调整这个值
    使得下界不断上式，来逼近对数似然函数的真实值，当不等式变为等式时，说明我们调整后的下界能够等价于原来的对数似然函数了，按照这个思路，我
    们的想法是，找到琴生不等式取等的条件，即必须满足：
    
        P(x_i,z_1;θ)/Q1(z_1) = P(x_i,z_2;θ)/Q1(z_2) = ... = P(x_i,z_n;θ)/Q1(z_n) = c（c为某个常数）
                        
        而由于Q(z_j)是我们引入的一个未知的分布，需要满足Jensen不等式的条件：
        
            sum Q(z_j) = 1 ，j=1,2,3,...,M
            
        根据这两个信息，我们可知：
        
            c = sum P(x_i,z_j;θ) 其中i为该轮的定值，j=1,2,3,...,n
            
            Q(z_j) = P(x_i,z_j;θ) / sum P(x_i,z_j;θ)   其中j=1,2,3,...,n
            
                    = P(x_i,z_j;θ) / P(xi;θ)
                    
                    = P(z_j|x_i;θ)
                
        至此，我们推出了固定参数θ之后，Q(z_j)的计算公式为P(z_j|x_i;θ)，就是一个后验概率，解决了Q(z_j)如何选择的问题
        
        如果我们能极大化刚刚的下界，那么我们的对数似然函数也可以极大化，即我们的任务是：
    
                arg max sum sum P(z_j|x_i;θ) * log P(x_i,z_j;θ)/P(z_j|x_i;θ)
                
        我们根据对数函数的性质，ln x/y = ln x - ln y ，P(z_j|x_i;θ) * log P(x_i,z_j;θ)/P(z_j|x_i;θ)可以展开为：
        
                P(z_j|x_i;θ) * log P(x_i,z_j;θ) - P(z_j|x_i;θ) * log P(x_i,z_j;θ)
                
        而我们在E步中，每轮有一个已知的θ_j，那么P(z_j|x_i;θ)的值是一个固定量，我们就可以把后面的式子去掉，最终我们的极大化任务为：
        
                arg max sum sum P(z_j|x_i;θ) * log P(x_i,z_j;θ)
                
        其中 sum P(z_j|x_i;θ) * log P(x_i,z_j;θ)可以理解为log P(x_i,z_j;θ)基于条件概率P(z_j|x_i;θ)分布的期望!
        
 3.EM算法的流程
 
    输入：观测到的数据 x = {x1, x2, x3, ..., xm}，联合分布p(x,z;θ)，条件分布p(z|x;θ)，最大迭代次数J.
    
    (1) 随机初始化模型参数θ的初值为θ_0
    
    (2) j=1, 2, 3, ... ,J开始迭代：
    
        E步：计算 联合分布 的条件概率的期望值
        
            Q(z_i) = P(z_i|x_i;θ_j)
            
            L(θ,θ_j) = sum sum Q(z_i) * log P(z_i,x_i|θ)

        M步：极大化L(θ,θ_j)，得到θ_j+1     
        
        如果θ_j+1已经收敛，就返回θ值，否则继续迭代下去
    
    输出：模型参数θ                               
    
 4. EM算法的收敛性
 
        EM算法可以保证收敛到一个稳定点，但是却不能保证收敛到全局的极大值点，因此它是局部最优的算法，当然，如果我们的优化目标L(θ,θj)是凸的，
    则EM算法可以保证收敛到全局最大值，这点和梯度下降法这样的迭代算法相同。
    
 5. EM算法的一些思考
 
    (1)传统EM算法对初始值敏感，聚类结果随不同的初始值而波动较大。总的来说，EM算法收敛的优劣很大程度上取决于其初始参数。
    
    (2)如果我们从算法思想的角度来思考EM算法，我们可以发现我们的算法里已知的是观察数据，未知的是隐含数据和模型参数
       在E步，我们所做的事情是固定模型参数的值，优化隐含数据的分布P(z|x,θ);
       在M步，我们所做的事情是固定隐含数据分布，优化模型参数的值θ;
       
    我们在学习EM算法的过程中，会发现它跟我们之前学过的某个算法的步骤很相似，那就是K-Means算法.

    在K-Means聚类时，每个聚类簇的质心是隐含数据。我们会假设K个初始化质心，即EM算法的E步；
    然后计算得到每个样本到质心的距离，并把它划分到最近的质心，即EM算法的M步。重复这个E步和M步，直到质心不再变化为止，这样就完成了K-Means聚类.
"""
