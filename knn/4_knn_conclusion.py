# encoding: utf-8
"""
 @project:ML_Algorithms
 @author: Jiang Hui
 @language:Python 3.7.2 [GCC 7.3.0] :: Anaconda, Inc. on linux
 @time: 2/22/19 2:47 PM
 @desc: KNN算法学习总结
"""

"""
 KNN如何选择合适的K值:
    如果选择较小的K值,就相当于用较小的邻域内的样本点进行预测,如果碰巧里面噪声较多,预测结果就会出错,导致过拟合;
    如果选择较大的K值,就相当于用较大的邻域内的样本点进行预测,这时不相似的样本点也会对预测起作用,导致欠拟合;
    推荐方法:
        step 1:用交叉验证法,将样本集分为训练集和验证集(如随机分成5份,4份用于训练,1份用于验证),轮流选取一份当验证集,其余几份用来训练,
        统计每一轮的正确率,累计求均值,得到的结果即为当前K值的分类准确率；
        step 2:更换K值,重复step 1,最终选取平均预测准确率最高的k值作为模型的k值
    
 KNN 算法的优缺点:
    1.优点:
        (1) 理论成熟，思想简单，可处理数值型或者离散型数据,既可以用来做分类也可以用来做回归
        (2) 可用于非线性分类(线性不可分的样本集)
        (3) 训练时间复杂度比支持向量机之类的算法低，仅为O(n),kd-tree为O(log n)
        (4) 受异常值(离群点)的影响小
    2.缺点:
        (1) 计算量大，尤其是特征数非常多的时候
        (2) 样本分布不平衡的时候,对于小类别的预测准确性低
        (3) 使用懒散学习方法，基本上不学习，每次预测都要计算一遍在样本集中的最邻近点
"""
